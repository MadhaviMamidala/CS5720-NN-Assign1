{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed84af21",
   "metadata": {},
   "source": [
    "# Neural Networks & Deep Learning: ICP1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7333f8df",
   "metadata": {},
   "source": [
    "1.Implement Naïve Bayes method using scikit-learn library\n",
    "Use dataset available with name glass\n",
    "Use train_test_split to create training and testing part\n",
    "Evaluate the model on test part using score and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1204a0a8",
   "metadata": {},
   "source": [
    "classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad40b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import classification_report, mean_squared_error, r2_score, f1_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74bbf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pandas we are reading glass data set\n",
    "\n",
    "glass_df = pd.read_csv('NNDL_Code and Data/glass.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a6fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about the Glass Dataset\n",
    "glass_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb2e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the dataset into dependent and Independent Variables\n",
    "\n",
    "y = glass_df['Type']\n",
    "X = glass_df.drop(['Type'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecdd4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d1d331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Dataset into Train (75%) and Test (25%) data samples\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f0bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using GaussianNB Naive Bayes Algorithm training and predicting the model\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"%  (X_test.shape[0], (y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification Report for the predicted data\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2343b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 Score for Naive Bayes\n",
    "f1 = f1_score(y_test, y_pred, average=None)\n",
    "print(\"f1 score with Naive Bayes : \", sum(f1)/len(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2887b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d379e2d7",
   "metadata": {},
   "source": [
    "2. Implement linear SVM method using scikit-learn\n",
    "Use the same dataset above\n",
    "Use train_test_split to create training and testing part\n",
    "Evaluate the model on test part using score and\n",
    "\n",
    "classification_report(y_true, y_pred)\n",
    "\n",
    "Which algorithm you got better accuracy? Can you justify why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281a4b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Support Vector Classifier \n",
    "\n",
    "svc = LinearSVC(tol=1e-5,max_iter = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c0ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Linear SVC and predicting test variables\n",
    "\n",
    "y_pred = svc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"%  (X_test.shape[0], (y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9fb446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report for Linear SVC\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b858dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 Score for Linear SVC\n",
    "f1 = f1_score(y_test, y_pred, average = None)\n",
    "print(\"f1 score with Linear SVC : \", sum(f1)/len(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ffc4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c15c478",
   "metadata": {},
   "source": [
    "With the above results Linear SVC performed better compared to Naive Bayes based on f1 scores\n",
    "\n",
    "SVMs are different from other Naive Bayes algorithm because of the way they choose the decision boundary that maximizes \n",
    "the distance from the nearest data points of all the classes. \n",
    "The decision boundary created by SVMs is called the maximum margin classifier or the maximum margin hyper plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10244912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8681c836",
   "metadata": {},
   "source": [
    "3. Implement Linear Regression using scikit-learn\n",
    "a) Import the given “Salary_Data.csv”\n",
    "b) Split the data in train_test partitions, such that 1/3 of the data is reserved as test subset.\n",
    "c) Train and predict the model.\n",
    "d) Calculate the mean_squared error.\n",
    "e) Visualize both train and test data using scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc355429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Salary Dataset\n",
    "salary_df = pd.read_csv('NNDL_Code and Data/Salary_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d19f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salary Dataset information\n",
    "salary_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767a6c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating dependent and Independent variables\n",
    "\n",
    "X = salary_df[['YearsExperience']]\n",
    "y = salary_df['Salary']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eac1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into Train (67%) and Test (33%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c3adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data with Linear Regression Model\n",
    "reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69f2244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd472fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test data\n",
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfafd907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error calculation\n",
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e34c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of training data with fitted regression line\n",
    "\n",
    "plt.scatter(X_train, y_train, color = \"red\")\n",
    "plt.plot(X_train, reg.predict(X_train), color = \"green\")\n",
    "plt.title(\"Salary vs Experience (Training set)\")\n",
    "plt.xlabel(\"Years of Experience\")\n",
    "plt.ylabel(\"Salary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of testing data with fitted regression line\n",
    "\n",
    "\n",
    "plt.scatter(X_test, y_test, color = \"red\")\n",
    "plt.plot(X_test, reg.predict(X_test), color = \"green\")\n",
    "plt.title(\"Salary vs Experience (Test set)\")\n",
    "plt.xlabel(\"Years of Experience\")\n",
    "plt.ylabel(\"Salary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e849772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
